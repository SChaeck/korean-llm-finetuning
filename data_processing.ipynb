{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import chardet\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 특정 키들이 있는지 확인하는 함수\n",
    "def has_required_keys(json_obj, required_keys):\n",
    "    return all(key in json_obj for key in required_keys)\n",
    "\n",
    "def detect_encoding(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        result = chardet.detect(f.read())\n",
    "        return result['encoding']\n",
    "\n",
    "def merge_and_shuffle_jsonl_files(input_folder, output_file, required_keys, max_entries):\n",
    "    # 모든 파일 경로를 리스트에 저장\n",
    "    jsonl_files = []\n",
    "    for root, dirs, files in os.walk(input_folder):\n",
    "        for file in files:\n",
    "            if file.endswith('.jsonl'):\n",
    "                jsonl_files.append(os.path.join(root, file))\n",
    "    \n",
    "    # 데이터를 임시로 저장할 리스트\n",
    "    data = []\n",
    "\n",
    "    # tqdm을 사용하여 진행 상태 표시\n",
    "    for file_path in tqdm(jsonl_files, desc=\"Processing JSONL files\"):\n",
    "        try:\n",
    "            encoding = detect_encoding(file_path)\n",
    "            with open(file_path, 'r', encoding=encoding) as infile:\n",
    "                for line in infile:\n",
    "                    try:\n",
    "                        json_obj = json.loads(line.strip())\n",
    "                        data.append(json_obj)\n",
    "                        # if has_required_keys(json_obj, required_keys):\n",
    "                        #     data.append(json_obj)\n",
    "                    except json.JSONDecodeError:\n",
    "                        print(f\"Error decoding JSON from file {file_path}: {line.strip()}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading file {file_path}: {e}\")\n",
    "\n",
    "    # 데이터를 셔플링\n",
    "    random.shuffle(data)\n",
    "\n",
    "    # 최대 항목 수 제한\n",
    "    # data = data[:max_entries]\n",
    "\n",
    "    # 출력 파일에 쓰기\n",
    "    with open(output_file, 'w', encoding='utf-8') as outfile:\n",
    "        for entry in data:\n",
    "            outfile.write(json.dumps(entry, ensure_ascii=False) + '\\n')\n",
    "\n",
    "# 사용 예시\n",
    "input_folder = 'dataset/02. Ko-MMLU'  # 순회할 폴더 경로를 입력하세요.\n",
    "output_file = 'dataset_merge/merged_output_Ko-MMLU.jsonl'  # 병합된 결과를 저장할 파일명을 입력하세요.\n",
    "required_keys = ['instruction', 'input', 'output', 'system', 'text']  # 확인할 키들을 입력하세요.\n",
    "max_entries = 50000  # 저장할 최대 항목 수\n",
    "\n",
    "# 함수 호출\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing JSONL files: 100%|██████████| 15/15 [26:49<00:00, 107.28s/it]\n"
     ]
    }
   ],
   "source": [
    "merge_and_shuffle_jsonl_files(input_folder, output_file, required_keys, max_entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing JSONL files:  70%|██████▉   | 46/66 [29:08<1:47:37, 322.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error reading file dataset/06. Ko-GSM8k/01. 숫자 연산 기계 독해/descriptive/01.경제/Training/경제.jsonl: 'charmap' codec can't decode byte 0x98 in position 110: character maps to <undefined>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing JSONL files:  76%|███████▌  | 50/66 [34:05<44:05, 165.37s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error reading file dataset/02. Ko-MMLU/04. 뉴스기사 기계독해/descriptive/span_inference/Training/span_inference.jsonl: 'utf-8' codec can't decode byte 0xec in position 188: invalid continuation byte\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing JSONL files:  79%|███████▉  | 52/66 [44:11<1:01:06, 261.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error reading file dataset/02. Ko-MMLU/04. 뉴스기사 기계독해/descriptive/text_entailment/Training/text_entailment.jsonl: 'utf-8' codec can't decode byte 0xb0 in position 4278: invalid start byte\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing JSONL files:  82%|████████▏ | 54/66 [1:17:56<2:21:32, 707.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error reading file dataset/02. Ko-MMLU/04. 뉴스기사 기계독해/descriptive/span_extraction/Training/span_extraction.jsonl: 'charmap' codec can't decode byte 0x98 in position 43: character maps to <undefined>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing JSONL files: 100%|██████████| 66/66 [1:39:33<00:00, 90.51s/it]   \n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m현재 셀 또는 이전 셀에서 코드를 실행하는 동안 Kernel이 충돌했습니다. \n",
      "\u001b[1;31m셀의 코드를 검토하여 가능한 오류 원인을 식별하세요. \n",
      "\u001b[1;31m자세한 내용을 보려면 <a href='https://aka.ms/vscodeJupyterKernelCrash'>여기</a>를 클릭하세요. \n",
      "\u001b[1;31m자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
     ]
    }
   ],
   "source": [
    "# merge_jsonl_files(input_folder, output_file, required_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting 30000 items: 100%|██████████| 30000/30000 [00:01<00:00, 25232.95it/s]\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m현재 셀 또는 이전 셀에서 코드를 실행하는 동안 Kernel이 충돌했습니다. \n",
      "\u001b[1;31m셀의 코드를 검토하여 가능한 오류 원인을 식별하세요. \n",
      "\u001b[1;31m자세한 내용을 보려면 <a href='https://aka.ms/vscodeJupyterKernelCrash'>여기</a>를 클릭하세요. \n",
      "\u001b[1;31m자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
     ]
    }
   ],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "def extract_first_n_items(input_file, output_file, n):\n",
    "    count = 0\n",
    "    with open(input_file, 'r', encoding='utf-8') as infile:\n",
    "        with open(output_file, 'w', encoding='utf-8') as outfile:\n",
    "            for line in tqdm(infile, desc=f\"Extracting {n} items\", total=n):\n",
    "                if count >= n:\n",
    "                    break\n",
    "                try:\n",
    "                    json_obj = json.loads(line.strip())\n",
    "                    json.dump(json_obj, outfile, ensure_ascii=False)\n",
    "                    outfile.write('\\n')\n",
    "                    count += 1\n",
    "                except json.JSONDecodeError:\n",
    "                    print(f\"Error decoding JSON from line: {line.strip()}\")\n",
    "\n",
    "# 입력과 출력 파일 경로 설정\n",
    "input_file = 'dataset_merge/merged_output_50000.jsonl'\n",
    "output_file = 'dataset_merge/merged_output_30000.jsonl'\n",
    "num_items_to_extract = 30000\n",
    "\n",
    "# 함수 호출\n",
    "extract_first_n_items(input_file, output_file, num_items_to_extract)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kollm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
